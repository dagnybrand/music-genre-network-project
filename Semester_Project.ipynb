{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagnybrand/music-genre-network-project/blob/main/Semester_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iR6h4fNoxMa_"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100, CIFAR10\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms.functional import resize\n",
        "from torchvision.transforms import CenterCrop\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "607r998LuLWt",
        "outputId": "522bca41-1464-4210-adc6-bda933592514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# design network\n",
        "# based on the CNN explainer https://poloclub.github.io/cnn-explainer/\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, numChannels = 3, numClasses = 10):\n",
        "    super(CNN, self).__init__()\n",
        "    self.classes = numClasses\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = numChannels, out_channels=64, kernel_size=(7, 7), stride = (6, 6))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 64, out_channels=128, kernel_size=(3, 3), stride = (1, 1))\n",
        "    self.conv4 = nn.Conv2d(in_channels = 128, out_channels=64, kernel_size=(3, 3), stride = (1, 1))\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=10240, out_features=1024)\n",
        "    self.fc2 = nn.Linear(in_features=1024, out_features=10)\n",
        "\n",
        "\n",
        "  # this evaluate function was taken from our Class Practicals\n",
        "  def evaluate(self, model, dataloader, classes):\n",
        "\n",
        "    # We need to switch the model into the evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    # For all test data samples:\n",
        "    for data in dataloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        # Count the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "\n",
        "          # If you want to see real and predicted labels for all samples:\n",
        "          # print(\"Real class: \" + classes[label] + \", predicted = \" + classes[prediction])\n",
        "\n",
        "          if label == prediction:\n",
        "            correct_pred[classes[label]] += 1\n",
        "          total_pred[classes[label]] += 1\n",
        "\n",
        "    # Calculate the overall accuracy on the test set\n",
        "    acc = sum(correct_pred.values()) / sum(total_pred.values())\n",
        "\n",
        "    return acc\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "     #x = resize(x, size=[256])\n",
        "\n",
        "     x = self.conv1(x)\n",
        "     x = self.relu(x)\n",
        "\n",
        "     x = self.conv2(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.maxpool(x)\n",
        "\n",
        "     x = self.conv4(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.maxpool(x)\n",
        "\n",
        "     x = torch.flatten(x, start_dim=1)\n",
        "     x = self.fc1(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.fc2(x)\n",
        "\n",
        "     return x"
      ],
      "metadata": {
        "id": "7TxGc4rtAH-2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file).drop(columns='Unnamed: 0')\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.le = preprocessing.LabelEncoder()\n",
        "        self.le.fit(['Blues', 'Classical', 'Country', 'Disco', 'Hip Hop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock'])\n",
        "\n",
        "        self.img_labels['Genre'] = self.le.transform(self.img_labels['Genre'])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_dir + self.le.inverse_transform([self.img_labels.iloc[idx, 1]])[0].lower().replace(\" \", \"\") + '/' + self.img_labels.iloc[idx, 0]\n",
        "        image = cv2.imread(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "hIe-m4gsqr2r"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "c31eX1nFxp3p"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "batch_size = 80\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Neural Networks/Semester Project/Project Data/train_data.csv'\n",
        "validate_path = '/content/drive/MyDrive/Neural Networks/Semester Project/Project Data/validate_data.csv'\n",
        "\n",
        "img_dir = '/content/drive/MyDrive/Neural Networks/Semester Project/Project Data/'\n",
        "\n",
        "train_data = CustomImageDataset(train_path, img_dir, transform = ToTensor())\n",
        "validate_data = CustomImageDataset(validate_path, img_dir, transform = ToTensor())\n",
        "\n",
        "# Prepare data loaders for train, validation and test data splits\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)\n",
        "val_loader = DataLoader(validate_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_starting_weights = \"/content/drive/MyDrive/Neural Networks/Semester Project/first_model.pth\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    mode = 'train'\n",
        "\n",
        "    # Path where you plan to save the best model during training\n",
        "    my_best_model = \"/content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\"\n",
        "    classes = ['Blues', 'Classical', 'Country', 'Disco', 'Hip Hop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock']\n",
        "\n",
        "\n",
        "    # Initialize the model and print out its configuration\n",
        "    model = CNN(numChannels = 3, numClasses = 10)\n",
        "\n",
        "    print(\"\\n\\nModel summary:\\n\\n\")\n",
        "    summary(model, input_size=(3, 288, 432))\n",
        "\n",
        "    if mode == \"train\":\n",
        "\n",
        "        print(\"\\n\\nTraining starts!\\n\\n\")\n",
        "\n",
        "        model.train()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "        #if my_starting_weights:\n",
        "            #print(f\"Loading the weights from {my_starting_weights} ...\")\n",
        "            #model.load_state_dict(torch.load(my_starting_weights))\n",
        "            #print(\"Successfully loaded the model checkpoint!\")\n",
        "\n",
        "        running_loss = .0\n",
        "        best_acc = .0\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Starting epoch {epoch + 1}\")\n",
        "            for idx, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "\n",
        "                # Get the inputs (data is a list of [inputs, labels])\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss\n",
        "\n",
        "            # Evaluate the accuracy after each epoch\n",
        "            acc = model.evaluate(model, val_loader, classes)\n",
        "            if acc > best_acc:\n",
        "                print(f\"Better validation accuracy achieved: {acc * 100:.2f}%\")\n",
        "                best_acc = acc\n",
        "                print(f\"Saving this model as: {my_best_model}\")\n",
        "                torch.save(model.state_dict(), my_best_model)\n",
        "\n",
        "    # And here we evaluate the trained model with the test data\n",
        "    elif mode == \"eval\":\n",
        "\n",
        "        print(\"\\n\\nValidating the trained model:\")\n",
        "        print(f\"Loading checkpoint from {my_best_model}\")\n",
        "        model.load_state_dict(torch.load(my_best_model))\n",
        "        acc = model.evaluate(model, test_loader, classes, device)\n",
        "        print(f\"Accuracy on the test (unknown) data: {acc * 100:.2f}%\")\n",
        "\n",
        "    else:\n",
        "        print(\"'mode' argument should either be 'train' or 'eval'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-0DzFW32Jsy",
        "outputId": "26736585-ef01-4013-b2e8-e863e405ab0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Model summary:\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 47, 71]           9,472\n",
            "              ReLU-2           [-1, 64, 47, 71]               0\n",
            "            Conv2d-3          [-1, 128, 45, 69]          73,856\n",
            "              ReLU-4          [-1, 128, 45, 69]               0\n",
            "         MaxPool2d-5          [-1, 128, 22, 34]               0\n",
            "            Conv2d-6           [-1, 64, 20, 32]          73,792\n",
            "              ReLU-7           [-1, 64, 20, 32]               0\n",
            "         MaxPool2d-8           [-1, 64, 10, 16]               0\n",
            "            Linear-9                 [-1, 1024]      10,486,784\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,654,154\n",
            "Trainable params: 10,654,154\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.42\n",
            "Forward/backward pass size (MB): 10.77\n",
            "Params size (MB): 40.64\n",
            "Estimated Total Size (MB): 52.84\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training starts!\n",
            "\n",
            "\n",
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 16.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 16.67%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 17.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 25.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 29.67%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 32.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 41.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 41.67%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 44.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 46.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 48.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 53.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 55.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 59.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:45<00:00,  5.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 59.67%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.83s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(numChannels = 3, numClasses = 10)\n",
        "best_model = my_best_model = \"/content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\"\n",
        "model.load_state_dict(torch.load(best_model))\n",
        "classes = ['Blues', 'Classical', 'Country', 'Disco', 'Hip Hop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock']\n",
        "\n",
        "\n",
        "train_acc = model.evaluate(model, train_loader, classes)\n",
        "val_acc = model.evaluate(model, val_loader, classes)\n",
        "\n",
        "print(f\"Accuracy when testing on training data: {train_acc*100}%\")\n",
        "print(f\"Accuracy when testing on validation data: {val_acc*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-D0oH9-13BU",
        "outputId": "9432594e-455b-482b-fbf9-86c7d45fdcea"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy when testing on training data: 85.12160228898426%\n",
            "Accuracy when testing on validation data: 59.66666666666667%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18vGt-O59W-IjtPtBvbgrzr_ETRq16wSf",
      "authorship_tag": "ABX9TyPqmLeA5VW5QbriYvKjcmz+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}