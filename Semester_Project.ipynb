{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagnybrand/music-genre-network-project/blob/main/Semester_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iR6h4fNoxMa_"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100, CIFAR10\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision.transforms.functional import resize\n",
        "from torchvision.transforms import CenterCrop\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "607r998LuLWt",
        "outputId": "05da507e-aee4-4658-8659-1c1cea58fcf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# design network\n",
        "# based on the CNN explainer https://poloclub.github.io/cnn-explainer/\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, numChannels = 3, numClasses = 10):\n",
        "    super(CNN, self).__init__()\n",
        "    self.classes = numClasses\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = numChannels, out_channels=64, kernel_size=(7, 7), stride = (6, 6))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 64, out_channels=128, kernel_size=(3, 3), stride = (1, 1))\n",
        "    #self.conv3 = nn.Conv2d(in_channels = 128, out_channels=128, kernel_size=(3, 3), stride = (1, 1))\n",
        "    self.conv4 = nn.Conv2d(in_channels = 128, out_channels=64, kernel_size=(3, 3), stride = (1, 1))\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=10240, out_features=1024)\n",
        "    self.fc2 = nn.Linear(in_features=1024, out_features=10)\n",
        "\n",
        "\n",
        "  def evaluate(self, model, dataloader, classes):\n",
        "\n",
        "        # We need to switch the model into the evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Prepare to count predictions for each class\n",
        "        correct_pred = {classname: 0 for classname in classes}\n",
        "        total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "        # For all test data samples:\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            # Count the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "\n",
        "                # If you want to see real and predicted labels for all samples:\n",
        "                # print(\"Real class: \" + classes[label] + \", predicted = \" + classes[prediction])\n",
        "\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "        # Calculate the overall accuracy on the test set\n",
        "        acc = sum(correct_pred.values()) / sum(total_pred.values())\n",
        "\n",
        "        return acc\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "     #x = resize(x, size=[256])\n",
        "\n",
        "     x = self.conv1(x)\n",
        "     x = self.relu(x)\n",
        "\n",
        "     x = self.conv2(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.maxpool(x)\n",
        "\n",
        "     #x = self.conv3(x)\n",
        "     #x = self.relu(x)\n",
        "\n",
        "     x = self.conv4(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.maxpool(x)\n",
        "\n",
        "     x = torch.flatten(x, 1)\n",
        "     x = self.fc1(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.fc2(x)\n",
        "\n",
        "     return x"
      ],
      "metadata": {
        "id": "7TxGc4rtAH-2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7byWWC5qvrhO"
      },
      "outputs": [],
      "source": [
        "# design network\n",
        "# based on the CNN explainer https://poloclub.github.io/cnn-explainer/\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, numChannels = 3, numClasses = 10):\n",
        "    super(CNN, self).__init__()\n",
        "    self.classes = numClasses\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels = numChannels, out_channels=10, kernel_size=(4, 4), stride = (1, 1))\n",
        "    self.conv2 = nn.Conv2d(in_channels = 10, out_channels=10, kernel_size=(3, 3), stride = (1, 1))\n",
        "    self.conv3 = nn.Conv2d(in_channels = 10, out_channels=10, kernel_size=(3, 3), stride = (2, 2))\n",
        "    self.conv4 = nn.Conv2d(in_channels = 10, out_channels=10, kernel_size=(3, 3), stride = (1, 1))\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "    self.fc = nn.Linear(in_features=17680, out_features=10)\n",
        "\n",
        "\n",
        "  def evaluate(self, model, dataloader, classes):\n",
        "\n",
        "        # We need to switch the model into the evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Prepare to count predictions for each class\n",
        "        correct_pred = {classname: 0 for classname in classes}\n",
        "        total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "        # For all test data samples:\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            # Count the correct predictions for each class\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "\n",
        "                # If you want to see real and predicted labels for all samples:\n",
        "                # print(\"Real class: \" + classes[label] + \", predicted = \" + classes[prediction])\n",
        "\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "        # Calculate the overall accuracy on the test set\n",
        "        acc = sum(correct_pred.values()) / sum(total_pred.values())\n",
        "\n",
        "        return acc\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "     #x = resize(x, size=[256])\n",
        "\n",
        "     x = self.conv1(x)\n",
        "     x = self.relu(x)\n",
        "\n",
        "     x = self.conv2(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.maxpool(x)\n",
        "\n",
        "     x = self.conv3(x)\n",
        "     x = self.relu(x)\n",
        "\n",
        "     x = self.conv4(x)\n",
        "     x = self.relu(x)\n",
        "     x = self.maxpool(x)\n",
        "\n",
        "     x = torch.flatten(x, 1)\n",
        "     x = self.fc(x)\n",
        "\n",
        "     return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file).drop(columns='Unnamed: 0')\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.le = preprocessing.LabelEncoder()\n",
        "        self.le.fit(['Blues', 'Classical', 'Country', 'Disco', 'Hip Hop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock'])\n",
        "\n",
        "        self.img_labels['Genre'] = self.le.transform(self.img_labels['Genre'])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_dir + self.le.inverse_transform([self.img_labels.iloc[idx, 1]])[0].lower().replace(\" \", \"\") + '/' + self.img_labels.iloc[idx, 0]\n",
        "        image = cv2.imread(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "hIe-m4gsqr2r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c31eX1nFxp3p"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "batch_size = 80\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Neural Networks/Semester Project/Project Data/train_data.csv'\n",
        "validate_path = '/content/drive/MyDrive/Neural Networks/Semester Project/Project Data/validate_data.csv'\n",
        "\n",
        "img_dir = '/content/drive/MyDrive/Neural Networks/Semester Project/Project Data/'\n",
        "\n",
        "#le = preprocessing.LabelEncoder()\n",
        "#le.fit(['Blues', 'Classical', 'Country', 'Disco', 'Hip Hop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock'])\n",
        "\n",
        "train_data = CustomImageDataset(train_path, img_dir, transform = ToTensor())\n",
        "validate_data = CustomImageDataset(validate_path, img_dir, transform = ToTensor())\n",
        "\n",
        "# Prepare data loaders for train, validation and test data splits\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)\n",
        "val_loader = DataLoader(validate_data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_starting_weights = \"/content/drive/MyDrive/Neural Networks/Semester Project/first_model.pth\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    mode = 'train'\n",
        "\n",
        "    # Path where you plan to save the best model during training\n",
        "    my_best_model = \"/content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\"\n",
        "    classes = ['Blues', 'Classical', 'Country', 'Disco', 'Hip Hop', 'Jazz', 'Metal', 'Pop', 'Reggae', 'Rock']\n",
        "\n",
        "\n",
        "    # Initialize the model and print out its configuration\n",
        "    model = CNN(numChannels = 3, numClasses = 10)\n",
        "\n",
        "    print(\"\\n\\nModel summary:\\n\\n\")\n",
        "    summary(model, input_size=(3, 288, 432))\n",
        "\n",
        "    if mode == \"train\":\n",
        "\n",
        "        print(\"\\n\\nTraining starts!\\n\\n\")\n",
        "\n",
        "        model.train()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "        #if my_starting_weights:\n",
        "            #print(f\"Loading the weights from {my_starting_weights} ...\")\n",
        "            #model.load_state_dict(torch.load(my_starting_weights))\n",
        "            #print(\"Successfully loaded the model checkpoint!\")\n",
        "\n",
        "        running_loss = .0\n",
        "        best_acc = .0\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"Starting epoch {epoch + 1}\")\n",
        "            for idx, data in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "\n",
        "                # Get the inputs (data is a list of [inputs, labels])\n",
        "                inputs, labels = data\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss\n",
        "\n",
        "            # Evaluate the accuracy after each epoch\n",
        "            acc = model.evaluate(model, val_loader, classes)\n",
        "            if acc > best_acc:\n",
        "                print(f\"Better validation accuracy achieved: {acc * 100:.2f}%\")\n",
        "                best_acc = acc\n",
        "                print(f\"Saving this model as: {my_best_model}\")\n",
        "                torch.save(model.state_dict(), my_best_model)\n",
        "\n",
        "    # And here we evaluate the trained model with the test data\n",
        "    elif mode == \"eval\":\n",
        "\n",
        "        print(\"\\n\\nValidating the trained model:\")\n",
        "        print(f\"Loading checkpoint from {my_best_model}\")\n",
        "        model.load_state_dict(torch.load(my_best_model))\n",
        "        acc = model.evaluate(model, test_loader, classes, device)\n",
        "        print(f\"Accuracy on the test (unknown) data: {acc * 100:.2f}%\")\n",
        "\n",
        "    else:\n",
        "        print(\"'mode' argument should either be 'train' or 'eval'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-0DzFW32Jsy",
        "outputId": "cf01cbdf-fd3a-4a84-95ed-260755c9bbee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Model summary:\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 47, 71]           9,472\n",
            "              ReLU-2           [-1, 64, 47, 71]               0\n",
            "            Conv2d-3          [-1, 128, 45, 69]          73,856\n",
            "              ReLU-4          [-1, 128, 45, 69]               0\n",
            "         MaxPool2d-5          [-1, 128, 22, 34]               0\n",
            "            Conv2d-6           [-1, 64, 20, 32]          73,792\n",
            "              ReLU-7           [-1, 64, 20, 32]               0\n",
            "         MaxPool2d-8           [-1, 64, 10, 16]               0\n",
            "            Linear-9                 [-1, 1024]      10,486,784\n",
            "             ReLU-10                 [-1, 1024]               0\n",
            "           Linear-11                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,654,154\n",
            "Trainable params: 10,654,154\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.42\n",
            "Forward/backward pass size (MB): 10.77\n",
            "Params size (MB): 40.64\n",
            "Estimated Total Size (MB): 52.84\n",
            "----------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training starts!\n",
            "\n",
            "\n",
            "Starting epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:44<00:00,  4.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 13.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:47<00:00,  5.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 18.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 21.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:42<00:00,  4.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 22.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:58<00:00,  6.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 24.67%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:51<00:00,  5.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 32.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 33.33%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:43<00:00,  4.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 40.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n",
            "Starting epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:50<00:00,  5.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Better validation accuracy achieved: 44.00%\n",
            "Saving this model as: /content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = my_best_model = \"/content/drive/MyDrive/Neural Networks/Semester Project/first_model_new.pth\"\n",
        "model.load_state_dict(torch.load(best_model))\n",
        "\n",
        "def test(testloader):\n",
        "  test_loss = 0.0\n",
        "  correct, total = 0,0\n",
        "\n",
        "  for data,label in testloader:\n",
        "      output = model(data)\n",
        "      for o,l in zip(torch.argmax(output,axis = 1),label):\n",
        "          if o == l:\n",
        "              correct += 1\n",
        "          total += 1\n",
        "      loss = criterion(output,label)\n",
        "      test_loss += loss.item() * data.size(0)\n",
        "  print(f'Testing Loss: {test_loss/len(testloader)}')\n",
        "  print(f'Correct Predictions: {correct}/{total}')\n",
        "  print(f'Accuracy: {correct/total * 100}%')\n",
        "\n",
        "test(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDJmGQ6RE3T_",
        "outputId": "c03ae82b-94b0-420d-af94-c9f01d30c7f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Loss: 118.8673613998625\n",
            "Correct Predictions: 325/699\n",
            "Accuracy: 46.49499284692418%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18vGt-O59W-IjtPtBvbgrzr_ETRq16wSf",
      "authorship_tag": "ABX9TyMK+tQety7eyxraC9Rs2qjV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}